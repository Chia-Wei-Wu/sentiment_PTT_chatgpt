{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+AvP1UB/F+m6LYvzWG1ON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chia-Wei-Wu/sentiment_PTT_chatgpt/blob/main/Cnsenti_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cnsenti"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBL3aJAJNyFG",
        "outputId": "c168c377-c21a-4fb1-f468-0ea64b0dd935"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cnsenti in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from cnsenti) (0.42.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cnsenti) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cnsenti import Sentiment\n",
        "import pandas as pd\n",
        "import json\n",
        "import jieba\n",
        "import csv"
      ],
      "metadata": {
        "id": "t9ouMeQ5QTIQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2XH64-iNiu1",
        "outputId": "9b63c1db-ac64-4fce-ba42-be72eadea1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = []\n",
        "data_frame = pd.DataFrame(columns=[\"title\",\"author\",\"date\",\"push\",\"url\",\"content\"])"
      ],
      "metadata": {
        "id": "sG-ZxYdNQCHK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/AI_Final/tec_2023.json','r',encoding=\"utf-8\") as read_file:\n",
        "  lines = read_file.readlines()\n",
        "  for line in lines:\n",
        "    data_dic = json.loads(line)\n",
        "    data_row = pd.DataFrame([data_dic])\n",
        "    data_frame = pd.concat([data_frame, data_row],ignore_index=True)\n",
        "#print(data_frame)"
      ],
      "metadata": {
        "id": "X5s6YOxwQCKL"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification by date\n",
        "data_frame[\"date\"] = pd.to_datetime(data_frame[\"date\"], format=\" %m/%d\")\n",
        "Jan_DF = []\n",
        "Feb_DF = []\n",
        "Mar_DF = []\n",
        "Apr_DF = []\n",
        "count_jan = 0\n",
        "count_feb = 0\n",
        "count_mar = 0\n",
        "count_apr = 0\n",
        "for index, row in data_frame.iterrows():\n",
        "  if row[\"date\"].month == 1:\n",
        "    Jan_DF.append(row)\n",
        "    count_jan += 1\n",
        "  elif row[\"date\"].month == 2:\n",
        "    Feb_DF.append(row)\n",
        "    count_feb += 1\n",
        "  elif row[\"date\"].month == 3:\n",
        "    Mar_DF.append(row)\n",
        "    count_mar += 1\n",
        "  elif row[\"date\"].month == 4:\n",
        "    Apr_DF.append(row)\n",
        "    count_apr += 1"
      ],
      "metadata": {
        "id": "9gieQ4c8QCMt"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_jan,count_feb,count_mar,count_apr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aS90yeasBcv",
        "outputId": "8a2cb68f-dff5-4c5d-c192-69549695b18b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "415 454 458 416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with Jan\n",
        "content_col_jan = []\n",
        "for row in Jan_DF:\n",
        "  content_col_jan.append(row[\"content\"])\n",
        "\n",
        "result_content_jan = []\n",
        "for row in content_col_jan:\n",
        "  row_content_jan = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_jan.append(word)\n",
        "  result_content_jan.append(row_content_jan)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_jan = []\n",
        "count_jan_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_jan:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_jan.append(row)\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Jan = []\n",
        "for sublist in having_GPT_jan:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Jan.append([result,sentence,label])\n",
        "\n",
        "with open('output_Jan_tec.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Jan)"
      ],
      "metadata": {
        "id": "aRmSqOTsQ4yt"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with Feb\n",
        "content_col_feb = []\n",
        "for row in Feb_DF:\n",
        "  content_col_feb.append(row[\"content\"])\n",
        "\n",
        "result_content_feb = []\n",
        "for row in content_col_feb:\n",
        "  row_content_feb = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_feb.append(word)\n",
        "  result_content_feb.append(row_content_feb)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_feb = []\n",
        "count_feb_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_feb:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_feb.append(row)\n",
        "    count_feb_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Feb = []\n",
        "for sublist in having_GPT_feb:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Feb.append([result,sentence,label])\n",
        "\n",
        "with open('output_Feb_tec.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Feb)"
      ],
      "metadata": {
        "id": "tScDqeB5YdY2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with mar\n",
        "content_col_mar = []\n",
        "for row in Mar_DF:\n",
        "  content_col_mar.append(row[\"content\"])\n",
        "\n",
        "result_content_mar = []\n",
        "for row in content_col_mar:\n",
        "  row_content_mar = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_mar.append(word)\n",
        "  result_content_mar.append(row_content_mar)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_mar = []\n",
        "count_mar_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_mar:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_mar.append(row)\n",
        "    count_mar_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Mar = []\n",
        "for sublist in having_GPT_mar:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Mar.append([result,sentence,label])\n",
        "\n",
        "with open('output_Mar_tec.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Mar)"
      ],
      "metadata": {
        "id": "KCz223T3dg6K"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with apr\n",
        "content_col_apr = []\n",
        "for row in Apr_DF:\n",
        "  content_col_apr.append(row[\"content\"])\n",
        "\n",
        "result_content_apr = []\n",
        "for row in content_col_apr:\n",
        "  row_content_apr = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_apr.append(word)\n",
        "  result_content_apr.append(row_content_apr)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_apr = []\n",
        "count_apr_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_apr:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_apr.append(row)\n",
        "    count_apr_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Apr = []\n",
        "for sublist in having_GPT_apr:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Apr.append([result,sentence,label])\n",
        "\n",
        "with open('output_Apr_tec.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Apr)"
      ],
      "metadata": {
        "id": "NEeIgEc1d27Q"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTT Stock Sentiment"
      ],
      "metadata": {
        "id": "-d28xuYQejzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = []\n",
        "data_frame = pd.DataFrame(columns=[\"title\",\"author\",\"date\",\"push\",\"url\",\"content\"])"
      ],
      "metadata": {
        "id": "cK9_zXbde0XE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/AI_Final/stock_2023.json','r',encoding=\"utf-8\") as read_file:\n",
        "  lines = read_file.readlines()\n",
        "  for line in lines:\n",
        "    data_dic = json.loads(line)\n",
        "    data_row = pd.DataFrame([data_dic])\n",
        "    data_frame = pd.concat([data_frame, data_row],ignore_index=True)\n",
        "#print(data_frame)"
      ],
      "metadata": {
        "id": "BD6gwKokeqYj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification by date\n",
        "data_frame[\"date\"] = pd.to_datetime(data_frame[\"date\"], format=\" %m/%d\")\n",
        "Jan_DF = []\n",
        "Feb_DF = []\n",
        "Mar_DF = []\n",
        "Apr_DF = []\n",
        "count_jan = 0\n",
        "count_feb = 0\n",
        "count_mar = 0\n",
        "count_apr = 0\n",
        "for index, row in data_frame.iterrows():\n",
        "  if row[\"date\"].month == 1:\n",
        "    Jan_DF.append(row)\n",
        "    count_jan += 1\n",
        "  elif row[\"date\"].month == 2:\n",
        "    Feb_DF.append(row)\n",
        "    count_feb += 1\n",
        "  elif row[\"date\"].month == 3:\n",
        "    Mar_DF.append(row)\n",
        "    count_mar += 1\n",
        "  elif row[\"date\"].month == 4:\n",
        "    Apr_DF.append(row)\n",
        "    count_apr += 1"
      ],
      "metadata": {
        "id": "sTn_Ug0Ge4XA"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with Jan\n",
        "content_col_jan = []\n",
        "for row in Jan_DF:\n",
        "  content_col_jan.append(row[\"content\"])\n",
        "\n",
        "result_content_jan = []\n",
        "for row in content_col_jan:\n",
        "  row_content_jan = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_jan.append(word)\n",
        "  result_content_jan.append(row_content_jan)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_jan = []\n",
        "count_jan_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_jan:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_jan.append(row)\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Jan = []\n",
        "for sublist in having_GPT_jan:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Jan.append([result,sentence,label])\n",
        "\n",
        "with open('output_Jan_stock.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Jan)"
      ],
      "metadata": {
        "id": "4d69QiXkfMSX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with Feb\n",
        "content_col_feb = []\n",
        "for row in Feb_DF:\n",
        "  content_col_feb.append(row[\"content\"])\n",
        "\n",
        "result_content_feb = []\n",
        "for row in content_col_feb:\n",
        "  row_content_feb = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_feb.append(word)\n",
        "  result_content_feb.append(row_content_feb)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_feb = []\n",
        "count_feb_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_feb:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_feb.append(row)\n",
        "    count_feb_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Feb = []\n",
        "for sublist in having_GPT_feb:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Feb.append([result,sentence,label])\n",
        "\n",
        "with open('output_Feb_stock.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Feb)"
      ],
      "metadata": {
        "id": "ISfJAk2af-lw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with mar\n",
        "content_col_mar = []\n",
        "for row in Mar_DF:\n",
        "  content_col_mar.append(row[\"content\"])\n",
        "\n",
        "result_content_mar = []\n",
        "for row in content_col_mar:\n",
        "  row_content_mar = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_mar.append(word)\n",
        "  result_content_mar.append(row_content_mar)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_mar = []\n",
        "count_mar_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_mar:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_mar.append(row)\n",
        "    count_mar_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Mar = []\n",
        "for sublist in having_GPT_mar:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Mar.append([result,sentence,label])\n",
        "\n",
        "with open('output_Mar_stock.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Mar)"
      ],
      "metadata": {
        "id": "Hg98Lmh9gIBU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing with apr\n",
        "content_col_apr = []\n",
        "for row in Apr_DF:\n",
        "  content_col_apr.append(row[\"content\"])\n",
        "\n",
        "result_content_apr = []\n",
        "for row in content_col_apr:\n",
        "  row_content_apr = []\n",
        "  words = jieba.cut(row)\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    row_content_apr.append(word)\n",
        "  result_content_apr.append(row_content_apr)\n",
        "\n",
        "#Find \"ChatGPT\"\n",
        "having_GPT_apr = []\n",
        "count_apr_GPT = 0\n",
        "chatgpt = \"chatgpt\"\n",
        "for row in result_content_apr:\n",
        "  if chatgpt in row:\n",
        "    having_GPT_apr.append(row)\n",
        "    count_apr_GPT += 1\n",
        "\n",
        "#find whole sentence with Sentiment\n",
        "senti = Sentiment()\n",
        "sentences_Apr = []\n",
        "for sublist in having_GPT_apr:\n",
        "  sentence = ''.join(sublist)\n",
        "  result = senti.sentiment_count(sentence)\n",
        "  #print(result,sentence)\n",
        "  label = \"\"\n",
        "  if result[\"pos\"] > result[\"neg\"] :\n",
        "    label = \"pos\"\n",
        "  elif result[\"pos\"] == result[\"neg\"] :\n",
        "    label = \"neu\"\n",
        "  else:\n",
        "    label = \"neg\"\n",
        "  sentences_Apr.append([result,sentence,label])\n",
        "\n",
        "with open('output_Apr_stock.csv','w',encoding='utf-8-sig', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Result', 'Sentence', 'label'])  \n",
        "    writer.writerows(sentences_Apr)"
      ],
      "metadata": {
        "id": "sVVOL4y4gMfu"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDWZgvMJgQRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}